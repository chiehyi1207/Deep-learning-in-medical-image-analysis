{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6993660,"sourceType":"datasetVersion","datasetId":3917417}],"dockerImageVersionId":30589,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pydicom","metadata":{"execution":{"iopub.status.busy":"2023-11-27T07:11:56.418428Z","iopub.execute_input":"2023-11-27T07:11:56.418730Z","iopub.status.idle":"2023-11-27T07:12:01.853528Z","shell.execute_reply.started":"2023-11-27T07:11:56.418700Z","shell.execute_reply":"2023-11-27T07:12:01.852718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport pydicom\nimport random\nfrom collections import Counter, defaultdict\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nimport torchvision.models as models\nfrom torch.utils.data import Subset\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score\nfrom torch.nn.utils import clip_grad_norm_","metadata":{"execution":{"iopub.status.busy":"2023-11-27T07:12:01.855305Z","iopub.execute_input":"2023-11-27T07:12:01.855596Z","iopub.status.idle":"2023-11-27T07:12:30.599990Z","shell.execute_reply.started":"2023-11-27T07:12:01.855564Z","shell.execute_reply":"2023-11-27T07:12:30.598956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2023-11-27T07:12:30.601084Z","iopub.execute_input":"2023-11-27T07:12:30.601497Z","iopub.status.idle":"2023-11-27T07:12:30.605136Z","shell.execute_reply.started":"2023-11-27T07:12:30.601468Z","shell.execute_reply":"2023-11-27T07:12:30.604452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Interpolate():\n    \n    def __init__(self, target_num = 22):\n        self.target_num = target_num\n    \n    def __call__(self, slices): # (3, XX, 512, 512)\n        slices = slices.unsqueeze(dim = 0) # (1, 3, XX, 512, 512)\n        slices = F.interpolate(\n                  slices, \n                  mode = 'trilinear',\n                  size = (self.target_num, slices.shape[-2], slices.shape[-1])) # (1, 3, 22, 512, 512)\n        return slices.squeeze() # (slices.squeeze(): (3, 22, 512, 512))\n\n# transform\nall_train_transform = [\n    Interpolate(target_num = 22)\n]\n\ntrain_transform = transforms.Compose(all_train_transform)","metadata":{"execution":{"iopub.status.busy":"2023-11-27T07:12:30.606090Z","iopub.execute_input":"2023-11-27T07:12:30.606338Z","iopub.status.idle":"2023-11-27T07:12:30.620353Z","shell.execute_reply.started":"2023-11-27T07:12:30.606314Z","shell.execute_reply":"2023-11-27T07:12:30.619662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MRI2DDataset(Dataset):\n    def __init__(self, df, transforms = None):\n        \n        root = \"/kaggle/input/hw3-data/hwk03_data/hwk03_data\"\n        self.ids = np.array(df[\"ID\"])\n        self.labels = torch.from_numpy(np.array(df[\"Disease\"]))\n        self.transforms = transforms\n        \n        paths = []\n        for ID in np.array(df[\"ID\"]):\n            path = os.path.join(root, \"DICOM\", str(ID).split('.')[0].zfill(7))\n            paths.append(path)\n        \n        self.images = []\n        \n        for path in paths:\n            all_slices = []\n            T1_root = os.path.join(root, \"DICOM\", path, \"T1\")\n            for filename in sorted(os.listdir(T1_root), key = lambda s: int(pydicom.dcmread(os.path.join(T1_root, s)).InstanceNumber)):\n                T1_image = []\n                T2_image = []\n                \n                # T1 images\n                img = pydicom.dcmread(os.path.join(T1_root, filename))\n                ww = img.WindowWidth\n                wc = img.WindowCenter\n                highest_visible_value = (ww + 2 * wc) / 2\n                lowest_visible_value = highest_visible_value - ww\n                \n                img = img.pixel_array\n                img = np.clip(img, lowest_visible_value, highest_visible_value)\n                img = 255 * (img - lowest_visible_value) / ww\n                img = cv2.resize(img, (512, 512))\n                \n                T1_image.append(img)\n                \n                # T2 images\n                img = pydicom.dcmread(os.path.join(root, \"DICOM\", path, \"T2\", filename))\n                ww = img.WindowWidth\n                wc = img.WindowCenter\n                highest_visible_value = (ww + 2 * wc) / 2\n                lowest_visible_value = highest_visible_value - ww\n                \n                img = img.pixel_array\n                img = np.clip(img, lowest_visible_value, highest_visible_value)\n                img = 255 * (img - lowest_visible_value) / ww\n                img = cv2.resize(img, (512, 512))\n                \n                T2_image.append(img)\n                \n                # T1T2 images\n                T1T2_image = (T1_image[0] + T2_image[0]) / 2\n                T1T2_image = torch.tensor(T1T2_image)\n                \n                T1_image = torch.tensor(T1_image[0])\n                T2_image = torch.tensor(T2_image[0])\n                \n                all_slices.append(torch.stack((T1_image, T2_image, T1T2_image), dim = 0))\n                \n            slices = torch.stack(all_slices, dim = 1)\n            \n            if self.transforms:\n                slices = self.transforms(slices) \n                slices = torch.transpose(slices, 0, 1) # (22, 3, 512, 512)\n            \n            image = []\n            for i in range(len(slices)):\n                image.append(slices[i].squeeze().float()) \n            self.images.append(image)\n                \n            \n    def __getitem__(self, index):\n        images = self.images[index]\n        label = self.labels[index]\n        \n        return images, label\n    \n    def __len__(self):\n        return(len(self.ids))","metadata":{"execution":{"iopub.status.busy":"2023-11-27T07:12:30.622436Z","iopub.execute_input":"2023-11-27T07:12:30.622667Z","iopub.status.idle":"2023-11-27T07:12:30.635775Z","shell.execute_reply.started":"2023-11-27T07:12:30.622644Z","shell.execute_reply":"2023-11-27T07:12:30.635056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class config:\n    \n    root = '/kaggle/input/hw3-data/hwk03_data/hwk03_data'\n    valid_prob = 0.2\n    \n    batch_size_early = 4\n    lr_early = 1e-4\n    epochs_early= 100\n    weight_decay_early = 1e-3\n    \n \n    \n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    seed = 42\n    \nprint(config.device)","metadata":{"execution":{"iopub.status.busy":"2023-11-27T07:12:30.636732Z","iopub.execute_input":"2023-11-27T07:12:30.636972Z","iopub.status.idle":"2023-11-27T07:12:30.652651Z","shell.execute_reply.started":"2023-11-27T07:12:30.636948Z","shell.execute_reply":"2023-11-27T07:12:30.651942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed):\n    # Set Python random seed\n    random.seed(seed)\n    \n    # Set NumPy random seed\n    np.random.seed(seed)\n    \n    # Set PyTorch random seed for CPU and GPU\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n    \n    # Set PyTorch deterministic operations for cudnn backend\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\ndef evaluator(preds, gts):\n    preds = preds.cpu().numpy() if isinstance(preds, torch.Tensor) else preds\n    gts = gts.cpu().numpy() if isinstance(gts, torch.Tensor) else gts\n    acc = accuracy_score(preds, gts)\n    f1 = f1_score(preds, gts, average=\"macro\")\n\n    return acc, f1\n\n\ndef train_one_epoch(model, train_loader, optimizer, scheduler, criterion, device):\n    model.train()\n    train_loss = 0.0\n    predictions, ground_truths = [], []\n\n    for batch_idx, (images, labels) in enumerate(train_loader):\n        # 將數據移動到指定的設備\n        \n        images = [img.to(device) for img in images]\n        labels = labels.to(device)\n        #print(\"Input shape:\", images[0].shape)\n        #print(\"Labels shape:\", labels.shape)\n        \n\n        optimizer.zero_grad()\n        logits = model(images)\n\n        loss = criterion(logits, labels)\n        loss.backward()\n\n        optimizer.step()\n        scheduler.step()\n\n        train_loss += loss.item()\n        preds = torch.argmax(logits, dim=1)\n\n        predictions.append(preds)\n        ground_truths.append(labels)\n\n    train_loss /= len(train_loader)\n\n    predictions = torch.cat(predictions)\n    ground_truths = torch.cat(ground_truths)\n    train_acc, train_f1 = evaluator(predictions, ground_truths)\n    torch.cuda.empty_cache()\n\n    return train_loss, 100*train_acc, 100*train_f1\n\ndef validation(model, valid_loader, criterion, device):\n    model.eval()\n    valid_loss = 0.0\n    predictions=[]\n    ground_truths = []\n\n    with torch.no_grad():\n        for batch_idx, (images, labels) in enumerate(valid_loader):\n            # 將數據移動到指定的設備\n            images = [img.to(device) for img in images]\n            labels = labels.to(device)\n            logits = model(images)\n            loss = criterion(logits, labels)\n\n            valid_loss += loss.item()\n            preds = torch.argmax(logits, dim=1)\n\n            predictions.append(preds)\n            ground_truths.append(labels)\n\n        valid_loss /= len(valid_loader)\n\n        predictions = torch.cat(predictions)\n        ground_truths = torch.cat(ground_truths)\n        valid_acc, valid_f1 = evaluator(predictions, ground_truths)\n        torch.cuda.empty_cache()\n\n    return valid_loss, 100*valid_acc, 100*valid_f1\n\n\n\ndef test(model, test_loader, device):\n    model.eval()\n    predictions_pro = []\n    predictions_stage = []\n\n    with torch.no_grad():\n        for batch_idx, (images, labels) in enumerate(test_loader):\n            # 將數據移動到指定的設備\n            images = [img.to(device) for img in images]\n            labels = labels.to(device)\n\n            logits = model(images)  \n            pred_pro = nn.functional.softmax(logits, dim=1)\n            pred_stage = torch.argmax(pred_pro, dim=1)\n\n            predictions_pro.append(pred_pro.cpu().numpy())\n            predictions_stage.append((pred_stage.cpu().numpy()))\n\n    predictions_pro = np.concatenate(predictions_pro, axis=0)\n    predictions_stage = np.concatenate(predictions_stage, axis=0)\n    torch.cuda.empty_cache()\n\n    return predictions_pro, predictions_stage\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-27T07:12:30.653620Z","iopub.execute_input":"2023-11-27T07:12:30.654098Z","iopub.status.idle":"2023-11-27T07:12:30.670312Z","shell.execute_reply.started":"2023-11-27T07:12:30.654070Z","shell.execute_reply":"2023-11-27T07:12:30.669604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Early Fusion model","metadata":{}},{"cell_type":"code","source":"\nclass EarlyFusion(nn.Module):\n    def __init__(self, num_classes, input_size=(3, 50, 50), out_prob=True, features_grad=False, num_input_channels=66):\n        super(EarlyFusion, self).__init__()\n\n        self.out_prob = out_prob\n\n        # VGG16 特徵提取層\n        vgg16 = models.vgg16(weights='IMAGENET1K_V1', progress=True)\n        vgg16.classifier = nn.Identity()\n\n        # 修改 VGG16 的第一個卷積層的輸入通道數\n        vgg16.features[0] = nn.Conv2d(num_input_channels, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n\n        # 固定/不固定特徵層的參數值\n        for param in vgg16.features.parameters():\n            param.requires_grad = features_grad\n        self.backend = vgg16\n\n        # 修改這裡的輸入維度為你的資料通道數 * VGG16 的輸出特徵大小\n        self.classifier = nn.Sequential(\n            nn.Linear(25088, 12544),\n            nn.ReLU(),\n            nn.Linear(12544, num_classes)\n            \n        )\n        self.softmax = nn.Softmax(dim=1)\n\n    def forward(self, x):\n        # 將所有切片的信息整合到單一的特徵表示中\n        x = torch.cat(x, dim=1)\n\n        # 使用 VGG16 特徵提取層\n        x = self.backend(x)\n        #print(x.size())\n\n        # 將特徵展平\n        x = x.view(x.size(0), -1)\n\n        # 通過全連接層進行分類\n        x = self.classifier(x)\n\n        # 如果需要機率輸出，應用 softmax\n        if self.out_prob:\n            x = self.softmax(x)\n\n        return x\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-27T07:12:30.671267Z","iopub.execute_input":"2023-11-27T07:12:30.671506Z","iopub.status.idle":"2023-11-27T07:12:30.684950Z","shell.execute_reply.started":"2023-11-27T07:12:30.671482Z","shell.execute_reply":"2023-11-27T07:12:30.684287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def early_fusion_modeling():\n\n    seed_everything(config.seed)\n    train_df = pd.read_csv(config.root+'/train.csv')\n    test_df = pd.read_csv(config.root+'/test.csv')\n\n\n    # Dataset\n    print(\"Early fusion \")\n    print(\"Initializing dataset...\")\n    dataset = MRI2DDataset(df = train_df, transforms = train_transform)\n    \n    print(\"Initializing test_dataset...\")\n    test_dataset = MRI2DDataset(df = test_df, transforms = train_transform)\n   \n    \n    # split training & validation dataset \n    n = len(dataset)\n    valid_size = int(n * config.valid_prob)\n    train_ids , valid_ids = train_test_split(\n     np.linspace(0, n - 1, n).astype(\"int\"),\n     test_size = valid_size,\n     random_state = config.seed,\n    )\n    print(f'Number of samples in train_dataset: {Counter(dataset.labels[train_ids])}')\n    print(f'Number of samples in val_dataset: {Counter(dataset.labels[valid_ids])}')\n    \n    # DataLoader\n    train_dataset = Subset(dataset, train_ids)\n    valid_dataset = Subset(dataset, valid_ids)\n    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=config.batch_size_early, shuffle=True)\n    valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=config.batch_size_early, shuffle=False)\n    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=config.batch_size_early, shuffle=False)\n\n    # settings\n    print(\"Early fusion training\")\n    print(\"Initializing model...\")\n    num_classes = len(Counter(dataset.labels[train_ids]))\n    model = EarlyFusion(num_classes = 2)\n    model.to(config.device)\n    criterion = nn.CrossEntropyLoss().to(config.device)\n    optimizer = torch.optim.Adam(model.parameters(), lr = config.lr_early, weight_decay = config.weight_decay_early)\n    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n        optimizer = optimizer,\n        epochs = config.epochs_early,\n        steps_per_epoch = train_loader.__len__(),\n        max_lr = config.lr_early,\n        anneal_strategy = 'cos'\n    )\n\n    # recordings\n    best_val_loss = float(\"inf\")\n    history = {\n      \"train\": {\n          \"loss\": [],\n          \"acc\": [],\n          \"f1\": []\n      },\n      \"valid\": {\n          \"loss\": [],\n          \"acc\": [],\n          \"f1\": []\n      },\n    }\n    \n    for epoch in range(config.epochs_early):\n        train_loss, train_acc, train_f1 = train_one_epoch(model, train_loader, optimizer, scheduler, criterion, config.device)\n        valid_loss, valid_acc, valid_f1 = validation(model, valid_loader, criterion, config.device)\n        \n        # Log the loss and validation result\n        history[\"train\"][\"loss\"].append(train_loss)\n        history[\"train\"][\"acc\"].append(train_acc)\n        history[\"train\"][\"f1\"].append(train_f1)\n        history[\"valid\"][\"loss\"].append(valid_loss)\n        history[\"valid\"][\"acc\"].append(valid_acc)\n        history[\"valid\"][\"f1\"].append(valid_f1)\n\n        print(f'Epoch[{epoch+1}/{config.epochs_early}], Train Loss: {train_loss:.7f}, Train Accuracy: {train_acc:.4f}%, Train F1: {train_f1:.4f}% | Valid Loss: {valid_loss:.7f}, Valid Accuracy: {valid_acc:.4f}%, Valid F1: {valid_f1:.4f}% | LR: {optimizer.state_dict()[\"param_groups\"][0][\"lr\"]:.6f}')\n\n        if valid_loss < best_val_loss:\n            save_file = {\n                \"model\": model.state_dict(),\n                \"optimizer\": optimizer.state_dict(),\n                \"scheduler\": scheduler.state_dict(),\n                \"epoch\": epoch,\n                \"args\": config\n            }\n            best_val_loss = valid_loss\n            torch.save(save_file, \"checkpoint_early.pth\")\n            \n    best_ckpt = torch.load(\"checkpoint_early.pth\", map_location=config.device)\n    model.load_state_dict(best_ckpt[\"model\"])\n\n    print(\"Early fusion plot\")\n    plt.figure(figsize=(12, 5))\n    plt.subplot(1, 2, 1)\n    plt.plot(range(config.epochs_early), history[\"train\"][\"loss\"], label='Training Loss')\n    plt.plot(range(config.epochs_early), history[\"valid\"][\"loss\"], label='Validation Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.title('Training and Validation Loss Curves')\n    plt.show()\n\n    plt.figure(figsize=(12, 5))\n    plt.subplot(1, 2, 1)\n    plt.plot(range(config.epochs_early), history[\"train\"][\"acc\"], label='Training Acc')\n    plt.plot(range(config.epochs_early), history[\"valid\"][\"acc\"], label='Validation Acc')\n    plt.xlabel('Epoch')\n    plt.ylabel('Acc')\n    plt.legend()\n    plt.title('Training and Validation Accuracy Curves')\n    plt.show()\n\n    plt.figure(figsize=(12, 5))\n    plt.subplot(1, 2, 1)\n    plt.plot(range(config.epochs_early), history[\"train\"][\"f1\"], label='Training F1')\n    plt.plot(range(config.epochs_early), history[\"valid\"][\"f1\"], label='Validation F1')\n    plt.xlabel('Epoch')\n    plt.ylabel('F1 Score')\n    plt.legend()\n    plt.title('Training and Validation F1 Score Curves')\n    plt.show()\n    \n    test_prediction_pro, test_prediction_stage = test(model, test_loader, config.device)\n    # 读取现有的test.csv文件\n    test_df = pd.read_csv('/kaggle/input/hw3-data/hwk03_data/hwk03_data/test.csv')\n\n    # 创建一个DataFrame包含预测结果\n    predictions = pd.DataFrame(test_prediction_pro, columns=[f'Disease({i})' for i in range(2)])\n    predictions['Disease'] = test_prediction_stage\n    predictions = predictions[['Disease(0)', 'Disease(1)', 'Disease']]\n    # 将预测结果添加到现有DataFrame中\n    test_df['Disease 0'] = predictions['Disease(0)']\n    test_df['Disease 1'] = predictions['Disease(1)']\n    \n    test_df['Disease'] = predictions['Disease']\n    # 另存为新的CSV文件\n    test_df.to_csv('early.csv', index=False)\n    print(\"early save\")\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-27T07:12:30.685943Z","iopub.execute_input":"2023-11-27T07:12:30.686181Z","iopub.status.idle":"2023-11-27T07:12:30.705272Z","shell.execute_reply.started":"2023-11-27T07:12:30.686157Z","shell.execute_reply":"2023-11-27T07:12:30.704585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def main():\n    \n    early_fusion_modeling()\n    \n    \nif __name__ == \"__main__\":\n    main()","metadata":{"execution":{"iopub.status.busy":"2023-11-27T07:12:30.706062Z","iopub.execute_input":"2023-11-27T07:12:30.706297Z","iopub.status.idle":"2023-11-27T07:52:45.435489Z","shell.execute_reply.started":"2023-11-27T07:12:30.706273Z","shell.execute_reply":"2023-11-27T07:52:45.434585Z"},"trusted":true},"execution_count":null,"outputs":[]}]}