{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6993660,"sourceType":"datasetVersion","datasetId":3917417}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pydicom","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport pydicom\nimport random\nfrom collections import Counter, defaultdict\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nimport torchvision.models as models\nfrom torch.utils.data import Subset\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score\nfrom torch.nn.utils import clip_grad_norm_","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Interpolate():\n    \n    def __init__(self, target_num = 22):\n        self.target_num = target_num\n    \n    def __call__(self, slices): # (3, XX, 512, 512)\n        slices = slices.unsqueeze(dim = 0) # (1, 3, XX, 512, 512)\n        slices = F.interpolate(\n                  slices, \n                  mode = 'trilinear',\n                  size = (self.target_num, slices.shape[-2], slices.shape[-1])) # (1, 3, 22, 512, 512)\n        return slices.squeeze() # (slices.squeeze(): (3, 22, 512, 512))\n\n# transform\nall_train_transform = [\n    Interpolate(target_num = 22)\n]\n\ntrain_transform = transforms.Compose(all_train_transform)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2D dataset","metadata":{}},{"cell_type":"code","source":"class MRI2DDataset(Dataset):\n    def __init__(self, df, transforms = None):\n        \n        root = \"/kaggle/input/hw3-data/hwk03_data/hwk03_data\"\n        self.ids = np.array(df[\"ID\"])\n        self.labels = torch.from_numpy(np.array(df[\"Disease\"]))\n        self.transforms = transforms\n        \n        paths = []\n        for ID in np.array(df[\"ID\"]):\n            path = os.path.join(root, \"DICOM\", str(ID).split('.')[0].zfill(7))\n            paths.append(path)\n        \n        self.images = []\n        \n        for path in paths:\n            all_slices = []\n            T1_root = os.path.join(root, \"DICOM\", path, \"T1\")\n            for filename in sorted(os.listdir(T1_root), key = lambda s: int(pydicom.dcmread(os.path.join(T1_root, s)).InstanceNumber)):\n                T1_image = []\n                T2_image = []\n                \n                # T1 images\n                img = pydicom.dcmread(os.path.join(T1_root, filename))\n                ww = img.WindowWidth\n                wc = img.WindowCenter\n                highest_visible_value = (ww + 2 * wc) / 2\n                lowest_visible_value = highest_visible_value - ww\n                \n                img = img.pixel_array\n                img = np.clip(img, lowest_visible_value, highest_visible_value)\n                img = 255 * (img - lowest_visible_value) / ww\n                img = cv2.resize(img, (512, 512))\n                \n                T1_image.append(img)\n                \n                # T2 images\n                img = pydicom.dcmread(os.path.join(root, \"DICOM\", path, \"T2\", filename))\n                ww = img.WindowWidth\n                wc = img.WindowCenter\n                highest_visible_value = (ww + 2 * wc) / 2\n                lowest_visible_value = highest_visible_value - ww\n                \n                img = img.pixel_array\n                img = np.clip(img, lowest_visible_value, highest_visible_value)\n                img = 255 * (img - lowest_visible_value) / ww\n                img = cv2.resize(img, (512, 512))\n                \n                T2_image.append(img)\n                \n                # T1T2 images\n                T1T2_image = (T1_image[0] + T2_image[0]) / 2\n                T1T2_image = torch.tensor(T1T2_image)\n                \n                T1_image = torch.tensor(T1_image[0])\n                T2_image = torch.tensor(T2_image[0])\n                \n                all_slices.append(torch.stack((T1_image, T2_image, T1T2_image), dim = 0))\n                \n            slices = torch.stack(all_slices, dim = 1)\n            \n            if self.transforms:\n                slices = self.transforms(slices) \n                slices = torch.transpose(slices, 0, 1) # (22, 3, 512, 512)\n            \n            image = []\n            for i in range(len(slices)):\n                image.append(slices[i].squeeze().float()) \n            self.images.append(image)\n                \n            \n    def __getitem__(self, index):\n        images = self.images[index]\n        label = self.labels[index]\n        \n        return images, label\n    \n    def __len__(self):\n        return(len(self.ids))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class config:\n    \n    root = '/kaggle/input/hw3-data/hwk03_data/hwk03_data'\n    valid_prob = 0.2\n    \n    \n    batch_size_late = 2\n    lr_late = 1e-5\n    epochs_late= 50\n    weight_decay_late = 1e-3\n    \n    \n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    seed = 42\n    \nprint(config.device)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed):\n    # Set Python random seed\n    random.seed(seed)\n    \n    # Set NumPy random seed\n    np.random.seed(seed)\n    \n    # Set PyTorch random seed for CPU and GPU\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n    \n    # Set PyTorch deterministic operations for cudnn backend\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\ndef evaluator(preds, gts):\n    preds = preds.cpu().numpy() if isinstance(preds, torch.Tensor) else preds\n    gts = gts.cpu().numpy() if isinstance(gts, torch.Tensor) else gts\n    acc = accuracy_score(preds, gts)\n    f1 = f1_score(preds, gts, average=\"macro\")\n\n    return acc, f1\n\n\ndef train_one_epoch(model, train_loader, optimizer, scheduler, criterion, device):\n    model.train()\n    train_loss = 0.0\n    predictions, ground_truths = [], []\n\n    for batch_idx, (images, labels) in enumerate(train_loader):\n        # 將數據移動到指定的設備\n        \n        images = [img.to(device) for img in images]\n        labels = labels.to(device)\n        #print(\"Input shape:\", images[0].shape)\n        #print(\"Labels shape:\", labels.shape)\n        \n\n        optimizer.zero_grad()\n        logits = model(images)\n\n        loss = criterion(logits, labels)\n        loss.backward()\n\n        optimizer.step()\n        scheduler.step()\n\n        train_loss += loss.item()\n        preds = torch.argmax(logits, dim=1)\n\n        predictions.append(preds)\n        ground_truths.append(labels)\n\n    train_loss /= len(train_loader)\n\n    predictions = torch.cat(predictions)\n    ground_truths = torch.cat(ground_truths)\n    train_acc, train_f1 = evaluator(predictions, ground_truths)\n    torch.cuda.empty_cache()\n\n    return train_loss, 100*train_acc, 100*train_f1\n\ndef validation(model, valid_loader, criterion, device):\n    model.eval()\n    valid_loss = 0.0\n    predictions=[]\n    ground_truths = []\n\n    with torch.no_grad():\n        for batch_idx, (images, labels) in enumerate(valid_loader):\n            # 將數據移動到指定的設備\n            images = [img.to(device) for img in images]\n            labels = labels.to(device)\n            logits = model(images)\n            loss = criterion(logits, labels)\n\n            valid_loss += loss.item()\n            preds = torch.argmax(logits, dim=1)\n\n            predictions.append(preds)\n            ground_truths.append(labels)\n\n        valid_loss /= len(valid_loader)\n\n        predictions = torch.cat(predictions)\n        ground_truths = torch.cat(ground_truths)\n        valid_acc, valid_f1 = evaluator(predictions, ground_truths)\n        torch.cuda.empty_cache()\n\n    return valid_loss, 100*valid_acc, 100*valid_f1\n\n\n\ndef test(model, test_loader, device):\n    model.eval()\n    predictions_pro = []\n    predictions_stage = []\n\n    with torch.no_grad():\n        for batch_idx, (images, labels) in enumerate(test_loader):\n            # 將數據移動到指定的設備\n            images = [img.to(device) for img in images]\n            labels = labels.to(device)\n\n            logits = model(images)  \n            pred_pro = nn.functional.softmax(logits, dim=1)\n            pred_stage = torch.argmax(pred_pro, dim=1)\n\n            predictions_pro.append(pred_pro.cpu().numpy())\n            predictions_stage.append((pred_stage.cpu().numpy()))\n\n    predictions_pro = np.concatenate(predictions_pro, axis=0)\n    predictions_stage = np.concatenate(predictions_stage, axis=0)\n    torch.cuda.empty_cache()\n\n    return predictions_pro, predictions_stage\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Late Fusion model","metadata":{}},{"cell_type":"code","source":"class Late_fusion(nn.Module):\n    def __init__(self, num_classes, input_size = (3, 50, 50), out_prob = True, features_grad = False): # 默認輸出為分到每一類的機率\n        super().__init__()\n        \n        # 決定是否要將輸出轉換為機率\n        self.out_prob = out_prob\n        \n        # 取出vgg16中的特徵層\n        vgg16 = models.vgg16(weights='IMAGENET1K_V1', progress = True)\n        vgg16.classifier = nn.Identity()\n        \n        # 固定/不固定特徵層的參數值\n        for param in vgg16.features.parameters():\n            param.requires_grad = features_grad\n        self.backend = vgg16\n        \n        \n        # 增加分類層\n        self.classifier = nn.Sequential(\n          nn.Linear(551936, num_classes) # 25088x22\n        )\n        self.softmax = nn.Softmax(dim=1)\n\n    def forward(self, x): # x: 22個(batch_size, 3, 512, 512)的list\n        outputs = []\n        for i in range(len(x)):\n            outputs.append(self.backend(x[i]))\n        \n        outputs = torch.cat(outputs, dim = 1)\n        outputs = self.classifier(outputs)\n        if self.out_prob:\n            outputs = self.softmax(outputs)\n        return outputs","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def late_fusion_modeling():\n\n    seed_everything(config.seed)\n    train_df = pd.read_csv(config.root+'/train.csv')\n    test_df = pd.read_csv(config.root+'/test.csv')\n\n\n    # Dataset\n    print(\"Late Fusion \")\n    print(\"Initializing dataset...\")\n    dataset = MRI2DDataset(df = train_df, transforms = train_transform)\n   \n    print(\"Initializing test_dataset...\")\n    test_dataset = MRI2DDataset(df = test_df, transforms = train_transform)\n\n    # split training & validation dataset \n    n = len(dataset)\n    valid_size = int(n * config.valid_prob)\n    train_ids , valid_ids = train_test_split(\n     np.linspace(0, n - 1, n).astype(\"int\"),\n     test_size = valid_size,\n     random_state = config.seed,\n    )\n    \n    print(f'Number of samples in train_dataset: {Counter(dataset.labels[train_ids])}')\n    print(f'Number of samples in val_dataset: {Counter(dataset.labels[valid_ids])}')\n    \n    \n    # DataLoader\n    train_dataset = Subset(dataset, train_ids)\n    valid_dataset = Subset(dataset, valid_ids)\n    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=config.batch_size_late, shuffle=True)\n    valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=config.batch_size_late, shuffle=False)\n    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=config.batch_size_late, shuffle=False)\n\n    # settings\n    print(\"Late Fusion training\")\n    print(\"Initializing model...\")\n    num_classes = len(Counter(dataset.labels[train_ids]))\n    model = Late_fusion(num_classes = 2)\n    model.to(config.device)\n    criterion = nn.CrossEntropyLoss().to(config.device)\n    optimizer = torch.optim.Adam(model.parameters(), lr = config.lr_late, weight_decay = config.weight_decay_late)\n    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n        optimizer = optimizer,\n        epochs = config.epochs_late,\n        steps_per_epoch = train_loader.__len__(),\n        max_lr = config.lr_late,\n        anneal_strategy = 'cos'\n    )\n\n    # recordings\n    best_val_loss = float(\"inf\")\n    history = {\n      \"train\": {\n          \"loss\": [],\n          \"acc\": [],\n          \"f1\": []\n      },\n      \"valid\": {\n          \"loss\": [],\n          \"acc\": [],\n          \"f1\": []\n      },\n    }\n    \n    for epoch in range(config.epochs_late):\n        train_loss, train_acc, train_f1 = train_one_epoch(model, train_loader, optimizer, scheduler, criterion, config.device)\n        valid_loss, valid_acc, valid_f1 = validation(model, valid_loader, criterion, config.device)\n        \n        # Log the loss and validation result\n        history[\"train\"][\"loss\"].append(train_loss)\n        history[\"train\"][\"acc\"].append(train_acc)\n        history[\"train\"][\"f1\"].append(train_f1)\n        history[\"valid\"][\"loss\"].append(valid_loss)\n        history[\"valid\"][\"acc\"].append(valid_acc)\n        history[\"valid\"][\"f1\"].append(valid_f1)\n\n        print(f'Epoch[{epoch+1}/{config.epochs_late}], Train Loss: {train_loss:.7f}, Train Accuracy: {train_acc:.4f}%, Train F1: {train_f1:.4f}% | Valid Loss: {valid_loss:.7f}, Valid Accuracy: {valid_acc:.4f}%, Valid F1: {valid_f1:.4f}% | LR: {optimizer.state_dict()[\"param_groups\"][0][\"lr\"]:.6f}')\n\n        if valid_loss < best_val_loss:\n            save_file = {\n                \"model\": model.state_dict(),\n                \"optimizer\": optimizer.state_dict(),\n                \"scheduler\": scheduler.state_dict(),\n                \"epoch\": epoch,\n                \"args\": config\n            }\n            best_val_loss = valid_loss\n            torch.save(save_file, \"checkpoint_late.pth\")\n            \n    best_ckpt = torch.load(\"checkpoint_late.pth\", map_location=config.device)\n    model.load_state_dict(best_ckpt[\"model\"])\n\n    print(\"Late Fusion plot\")\n    plt.figure(figsize=(12, 5))\n    plt.subplot(1, 2, 1)\n    plt.plot(range(config.epochs_late), history[\"train\"][\"loss\"], label='Training Loss')\n    plt.plot(range(config.epochs_late), history[\"valid\"][\"loss\"], label='Validation Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.title('Training and Validation Loss Curves')\n    plt.show()\n\n    plt.figure(figsize=(12, 5))\n    plt.subplot(1, 2, 1)\n    plt.plot(range(config.epochs_late), history[\"train\"][\"acc\"], label='Training Acc')\n    plt.plot(range(config.epochs_late), history[\"valid\"][\"acc\"], label='Validation Acc')\n    plt.xlabel('Epoch')\n    plt.ylabel('Acc')\n    plt.legend()\n    plt.title('Training and Validation Accuracy Curves')\n    plt.show()\n\n    plt.figure(figsize=(12, 5))\n    plt.subplot(1, 2, 1)\n    plt.plot(range(config.epochs_late), history[\"train\"][\"f1\"], label='Training F1')\n    plt.plot(range(config.epochs_late), history[\"valid\"][\"f1\"], label='Validation F1')\n    plt.xlabel('Epoch')\n    plt.ylabel('F1 score')\n    plt.legend()\n    plt.title('Training and Validation F1 Score Curves')\n    plt.show()\n    \n    test_prediction_pro, test_prediction_stage = test(model, test_loader, config.device)\n    # 读取现有的test.csv文件\n    #print(test_prediction_pro)\n    #print(test_prediction_stage)\n    test_df = pd.read_csv('/kaggle/input/hw3-data/hwk03_data/hwk03_data/test.csv')\n    # 创建一个DataFrame包含预测结果\n    predictions = pd.DataFrame(test_prediction_pro, columns=[f'Disease({i})' for i in range(2)])\n    predictions['Disease'] = test_prediction_stage\n    predictions = predictions[['Disease(0)', 'Disease(1)', 'Disease']]\n    # 将预测结果添加到现有DataFrame中\n    test_df['Disease 0'] = predictions['Disease(0)']\n    test_df['Disease 1'] = predictions['Disease(1)']\n    \n    test_df['Disease'] = predictions['Disease']\n    # 另存为新的CSV文件\n    test_df.to_csv('late.csv', index=False)\n    print(\"late save\")\n\n\n\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def main():\n   \n\n    late_fusion_modeling()\n   \n    \n    \nif __name__ == \"__main__\":\n    main()","metadata":{},"execution_count":null,"outputs":[]}]}