{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6861609,"sourceType":"datasetVersion","datasetId":3917278}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Packages","metadata":{}},{"cell_type":"code","source":"!pip install torchsummary","metadata":{"execution":{"iopub.status.busy":"2023-11-23T07:22:00.638983Z","iopub.execute_input":"2023-11-23T07:22:00.639652Z","iopub.status.idle":"2023-11-23T07:22:12.352459Z","shell.execute_reply.started":"2023-11-23T07:22:00.639624Z","shell.execute_reply":"2023-11-23T07:22:12.351400Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pydicom\nimport pandas as pd\nimport numpy as np\nimport random\nfrom collections import Counter, defaultdict\n\nimport matplotlib.pyplot as plt\nimport plotly.express as px\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torch.nn.init as init\n\nfrom torch.utils.data import Dataset, Subset, DataLoader\nfrom torchvision.transforms import v2\nimport torchvision.models as models # VGG16, ResNet50\nfrom torchsummary import summary # summary for model印出模型的資料\nfrom torch.utils.tensorboard import SummaryWriter\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, f1_score\nfrom collections import OrderedDict","metadata":{"execution":{"iopub.status.busy":"2023-11-23T07:22:12.354348Z","iopub.execute_input":"2023-11-23T07:22:12.354672Z","iopub.status.idle":"2023-11-23T07:22:12.362691Z","shell.execute_reply.started":"2023-11-23T07:22:12.354644Z","shell.execute_reply":"2023-11-23T07:22:12.361735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Configuration","metadata":{}},{"cell_type":"code","source":"class config:\n    \n    root = '/kaggle/input/d/chieh7/hw2-data/hwk02_data'\n    valid_prob = 0.2\n    batch_size_VGG = 14\n    batch_size_Res = 16\n    lr_VGG = 1e-4\n    lr_Res = 1e-4\n    epochs_VGG = 300\n    epochs_Res = 300\n    weight_decay_VGG = 1e-5\n    weight_decay_Res = 1e-5\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    seed = 42\n    \nprint(config.device)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-23T07:22:32.661024Z","iopub.execute_input":"2023-11-23T07:22:32.661430Z","iopub.status.idle":"2023-11-23T07:22:32.668299Z","shell.execute_reply.started":"2023-11-23T07:22:32.661405Z","shell.execute_reply":"2023-11-23T07:22:32.667325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dicom_path = '/DICOM/A1406/00010019'\ndicom_file = pydicom.dcmread(config.root+dicom_path)\nprint(dicom_file)#包括DICOM文件中的所有標籤（例如患者信息、影像信息等）。","metadata":{"execution":{"iopub.status.busy":"2023-11-23T07:22:36.853917Z","iopub.execute_input":"2023-11-23T07:22:36.854770Z","iopub.status.idle":"2023-11-23T07:22:36.890612Z","shell.execute_reply.started":"2023-11-23T07:22:36.854737Z","shell.execute_reply":"2023-11-23T07:22:36.889721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(dicom_file.WindowCenter, dicom_file.WindowWidth)\nimages = dicom_file.pixel_array\nprint(images.shape)\nplt.figure(figsize=(16, 20))\n\nfor i in range(images.shape[0]):\n    plt.subplot(5,4,i+1)\n    plt.imshow(images[i]) #gray\n    plt.title(f'slice {i+1}')\n    plt.axis('off')\n    plt.subplots_adjust(wspace=None, hspace=None)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-23T07:22:42.500800Z","iopub.execute_input":"2023-11-23T07:22:42.501503Z","iopub.status.idle":"2023-11-23T07:22:45.031709Z","shell.execute_reply.started":"2023-11-23T07:22:42.501470Z","shell.execute_reply":"2023-11-23T07:22:45.030716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(config.root+'/train.csv')\ntrain_df\n#index\ntest_df = pd.read_csv(config.root+'/test.csv')\ntest_df\n","metadata":{"execution":{"iopub.status.busy":"2023-11-23T06:54:46.966612Z","iopub.execute_input":"2023-11-23T06:54:46.966995Z","iopub.status.idle":"2023-11-23T06:54:46.999717Z","shell.execute_reply.started":"2023-11-23T06:54:46.966965Z","shell.execute_reply":"2023-11-23T06:54:46.998842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Input Data","metadata":{}},{"cell_type":"code","source":"train_data = pd.read_csv(config.root+'/train.csv')\ntest_data = pd.read_csv(config.root+'/test.csv')\nprint(f'Number of training samples: {train_data.shape[0]}')\nprint(f'Number of testing samples: {test_data.shape[0]}')","metadata":{"execution":{"iopub.status.busy":"2023-11-23T06:54:53.036993Z","iopub.execute_input":"2023-11-23T06:54:53.037373Z","iopub.status.idle":"2023-11-23T06:54:53.049907Z","shell.execute_reply.started":"2023-11-23T06:54:53.037345Z","shell.execute_reply":"2023-11-23T06:54:53.048862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data['Stage'].value_counts().sort_index()","metadata":{"execution":{"iopub.status.busy":"2023-11-23T06:54:55.442969Z","iopub.execute_input":"2023-11-23T06:54:55.443818Z","iopub.status.idle":"2023-11-23T06:54:55.451485Z","shell.execute_reply.started":"2023-11-23T06:54:55.443784Z","shell.execute_reply":"2023-11-23T06:54:55.450622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Defined functions","metadata":{}},{"cell_type":"code","source":"def seed_everything(seed):\n    # Set Python random seed\n    random.seed(seed)\n    \n    # Set NumPy random seed\n    np.random.seed(seed)\n    \n    # Set PyTorch random seed for CPU and GPU\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n    \n    # Set PyTorch deterministic operations for cudnn backend\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\ndef evaluator(preds, gts):\n    preds = preds.cpu().numpy() if isinstance(preds, torch.Tensor) else preds\n    gts = gts.cpu().numpy() if isinstance(gts, torch.Tensor) else gts\n    acc = accuracy_score(preds, gts)\n    f1 = f1_score(preds, gts, average=\"macro\")\n\n    return acc, f1\n\ndef train_one_epoch(model, train_loader, optimizer, scheduler, criterion, device):\n    model.train()\n    train_loss = .0\n    predictions, ground_truths = [], []\n    for images, ages, genders, labels in train_loader:\n        images = images.to(device=device, dtype=torch.float)\n        ages = ages.to(device=device, dtype=torch.float)\n        genders = genders.to(device=device, dtype=torch.float)\n        labels = labels.to(device=device, dtype=torch.long)\n\n        optimizer.zero_grad()\n        logits = model(images, ages, genders)\n        labels = torch.sub(labels, 1) # labels 1, 2, 3 -> 0, 1, 2\n        loss = criterion(logits, labels)\n        loss.backward()\n\n        optimizer.step()\n        scheduler.step()\n\n        train_loss += loss.item()\n        preds = torch.argmax(logits, dim=1)\n\n        predictions.append(preds)\n        ground_truths.append(labels)\n\n    train_loss /= len(train_loader)\n\n    predictions = torch.cat(predictions)\n    ground_truths = torch.cat(ground_truths)\n    train_acc, train_f1 = evaluator(predictions, ground_truths)\n\n    return train_loss, 100*train_acc, 100*train_f1\n\ndef validation(model, valid_loader, criterion, device):\n    model.eval()\n    valid_loss = .0\n    predictions, ground_truths = [], []\n    with torch.no_grad():\n        for images, ages, genders, labels in valid_loader:\n            images = images.to(device=device, dtype=torch.float)\n            ages = ages.to(device=device, dtype=torch.float)\n            genders = genders.to(device=device, dtype=torch.float)\n            labels = labels.to(device=device, dtype=torch.long)\n\n            logits = model(images, ages, genders)\n            labels = torch.sub(labels, 1) # labels 1, 2, 3 -> 0, 1, 2\n            loss = criterion(logits, labels)\n\n            valid_loss += loss.item()\n            preds = torch.argmax(logits, dim=1)\n\n            predictions.append(preds)\n            ground_truths.append(labels)\n\n        valid_loss /= len(valid_loader)\n\n        predictions = torch.cat(predictions)\n        ground_truths = torch.cat(ground_truths)\n        valid_acc, valid_f1 = evaluator(predictions, ground_truths)\n    return valid_loss, 100*valid_acc, 100*valid_f1\n\ndef test(model,test_loader, device):\n    model.eval()\n    predictions_pro = []\n    predictions_stage = []\n    with torch.no_grad():\n        for images, ages, genders,labels in test_loader:\n            images = images.to(device=device, dtype=torch.float)\n            ages = ages.to(device=device, dtype=torch.float)\n            genders = genders.to(device=device, dtype=torch.float)\n            labels = labels.to(device=device, dtype=torch.long)\n            logits = model(images, ages, genders)\n            pred_pro = nn.functional.softmax(logits, dim=1)\n            pred_stage = torch.argmax(pred_pro, dim=1)\n            predictions_pro.append(pred_pro.cpu().numpy())\n            predictions_stage.append((pred_stage.cpu().numpy()+1))\n             \n    predictions_pro = np.concatenate(predictions_pro, axis=0)\n    predictions_stage = np.concatenate(predictions_stage, axis=0)\n   \n    \n    return  predictions_pro, predictions_stage","metadata":{"execution":{"iopub.status.busy":"2023-11-23T07:22:50.780918Z","iopub.execute_input":"2023-11-23T07:22:50.781795Z","iopub.status.idle":"2023-11-23T07:22:50.803279Z","shell.execute_reply.started":"2023-11-23T07:22:50.781763Z","shell.execute_reply":"2023-11-23T07:22:50.802451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Defined Dataset","metadata":{}},{"cell_type":"code","source":"class ParkinsonsDataset(Dataset):\n    def __init__(self, df, transforms = None): # 將所有資料提出\n        self.ages = np.array(df['Age']) # 年齡\n        self.genders = np.array(df['Gender']) # 性別\n        self.labels = np.array(df['Stage']) # 標籤\n        self.indexs = np.array(df['index']) # 起始張數\n        self.paths = np.array(df['FilePath']) # 影像路徑\n        self.images = []\n\n        # 影像前處理\n        for index, path in zip(self.indexs, self.paths):\n            image = pydicom.dcmread(config.root+path).pixel_array\n            image = torch.tensor(image.astype(np.float32))\n            image = image[index-1:index+2, :, :] # 取指定張數和前後共三個, image size = (3, 128, 128)\n            if transforms:\n                image = transforms(image)\n            self.images.append(image)\n\n\n    def __len__(self):\n        return len(self.labels) # label數量\n\n    def __getitem__(self, idx): # 找出指定的資料\n        age = torch.tensor(self.ages[idx], dtype=torch.float32)\n        gender = torch.tensor(self.genders[idx], dtype=torch.float32)\n        label = self.labels[idx]\n        image = self.images[idx]\n\n        return image, age, gender, label\n\n# Transformation\nclass My_normalize(object): # 自定義的類別\n    # def __init__(self): # 宣告此類別中會使用到的變數\n\n    def __call__(self, image): # 定義有image之後要進行的資料處理\n        new_image = (image - image.mean())/(image.max() - image.min())\n\n        return new_image\n\nMy_transforms = v2.Compose([\n    # 在v2中內建的func\n    v2.CenterCrop(size = (50, 50)),\n    # 自定義的func\n    My_normalize()\n])","metadata":{"execution":{"iopub.status.busy":"2023-11-23T07:22:54.681668Z","iopub.execute_input":"2023-11-23T07:22:54.682385Z","iopub.status.idle":"2023-11-23T07:22:54.697497Z","shell.execute_reply.started":"2023-11-23T07:22:54.682344Z","shell.execute_reply":"2023-11-23T07:22:54.696347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = ParkinsonsDataset(train_df, transforms = My_transforms)\ntest_dataset = ParkinsonsDataset(test_df, transforms = My_transforms)\nprint(f\"Number of training samples: {len(dataset)}\")\nprint(f\"Number of testing samples: {len(test_dataset)}\")\n\ntrain_labels_distribution = Counter(dataset.labels)#使用 Counter 函式計算資料集中各標籤的數量\nprint(train_labels_distribution)\nx = [key.astype(str) for key in train_labels_distribution.keys()]\ny = [value for value in train_labels_distribution.values()]\nplt.bar(x, y, color = 'lightcoral')\nplt.ylabel(\"Number of samples\")\nplt.title(\"Distribution of labels in training dataset\")\nplt.xticks()#設定 x 軸的刻度標籤\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-23T07:22:59.045678Z","iopub.execute_input":"2023-11-23T07:22:59.046526Z","iopub.status.idle":"2023-11-23T07:23:00.104581Z","shell.execute_reply.started":"2023-11-23T07:22:59.046491Z","shell.execute_reply":"2023-11-23T07:23:00.103728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"subdf = train_df[(train_df['Gender'] == 1) & (train_df['Stage'] == 1)]\nsubdf.shape[0]\nmale = [train_df[(train_df['Gender'] == 1) & (train_df['Stage'] == i)].shape[0] for i in range(1, 4)]\nfemale = [train_df[(train_df['Gender'] == 0) & (train_df['Stage'] == i)].shape[0] for i in range(1, 4)]\nprint(male, female)\nx_axis = np.arange(len(x))\nplt.bar(x_axis - 0.2, male, 0.4, label = 'Male', color = 'cornflowerblue')\nplt.bar(x_axis + 0.2, female, 0.4, label = 'Female', color = 'lightcoral')\nplt.xticks(x_axis, x)\nplt.xlabel(\"Stages\")\nplt.ylabel(\"Number of samples\")\nplt.title(\"Number of samples in each group\")\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-23T07:23:02.451688Z","iopub.execute_input":"2023-11-23T07:23:02.452063Z","iopub.status.idle":"2023-11-23T07:23:02.660944Z","shell.execute_reply.started":"2023-11-23T07:23:02.452034Z","shell.execute_reply":"2023-11-23T07:23:02.660071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df = [train_df[train_df['Stage'] == i]['Age'] for i in range(1, 4)]\nplt.boxplot(sub_df)\nplt.xlabel(\"Stages\")\nplt.ylabel(\"Number of samples\")\nplt.title(\"Number of samples in each group\")\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-23T07:23:06.034635Z","iopub.execute_input":"2023-11-23T07:23:06.034992Z","iopub.status.idle":"2023-11-23T07:23:06.234094Z","shell.execute_reply.started":"2023-11-23T07:23:06.034965Z","shell.execute_reply":"2023-11-23T07:23:06.233211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_data = [np.random.normal(0, std, size=100) for std in range(1, 4)]\nlen(all_data)\nn = len(dataset)\nvalid_size = int(n * 0.3) # 取30%作為validation\ntrain_ids , vaild_ids = train_test_split(\n    np.linspace(0, n - 1, n).astype(\"int\"),\n    test_size = valid_size,\n    random_state=42,\n)\ntrain_dataset = Subset(dataset, train_ids)\nval_dataset = Subset(dataset, vaild_ids)\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True)\nval_loader = torch.utils.data.DataLoader(val_dataset, batch_size=16, shuffle=False)\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=16, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T07:23:08.882553Z","iopub.execute_input":"2023-11-23T07:23:08.883400Z","iopub.status.idle":"2023-11-23T07:23:08.893256Z","shell.execute_reply.started":"2023-11-23T07:23:08.883362Z","shell.execute_reply":"2023-11-23T07:23:08.892155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for images, ages, genders, labels in train_loader:\n        images = images.to(device=config.device, dtype=torch.float)\n        ages = ages.to(device=config.device, dtype=torch.float)\n        genders = genders.to(device=config.device, dtype=torch.float)\n        labels = labels.to(device=config.device, dtype=torch.long)\n        print(images.shape)\n        print(images)\n        #print(labels)\n        #print(\"torch\")\n        #labels = torch.sub(labels,0) # labels 1, 2, 3 -> 0, 1, 2\n        #print(labels)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T07:34:15.442604Z","iopub.execute_input":"2023-11-23T07:34:15.442979Z","iopub.status.idle":"2023-11-23T07:34:15.614775Z","shell.execute_reply.started":"2023-11-23T07:34:15.442954Z","shell.execute_reply":"2023-11-23T07:34:15.613821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images, ages, genders, labels = next(iter(train_loader))\n\nplt.figure(figsize=(12, 64)) # (寬, 長)\n\nfor i, (image ,label) in enumerate(zip(images, labels)):\n    for j in range(3):\n        plt.subplot(16, 3,i*3+j+1)\n        plt.title(label)\n        plt.imshow(image[j])\n        plt.axis('off')\n        plt.subplots_adjust(wspace=None, hspace=None)\n\nprint(f\"Image shape: {images.shape}, label shape {label.shape}\")","metadata":{"execution":{"iopub.status.busy":"2023-11-03T11:36:09.189445Z","iopub.execute_input":"2023-11-03T11:36:09.189739Z","iopub.status.idle":"2023-11-03T11:36:13.469586Z","shell.execute_reply.started":"2023-11-03T11:36:09.189706Z","shell.execute_reply":"2023-11-03T11:36:13.468709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Redefined VGG16","metadata":{}},{"cell_type":"code","source":"class VGGplus(nn.Module):\n    def __init__(self, num_classes, input_size = (3, 50, 50), out_prob = True, features_grad = False): # 默認輸出為分到每一類的機率\n        super().__init__()\n        self.max_grad_norm = 0.1  \n        # 決定是否要將輸出轉換為機率\n        self.out_prob = out_prob\n        \n        # 取出vgg16中的特徵層\n        vgg16 = models.vgg16(weights='IMAGENET1K_V1', progress = True)\n        vgg16.features[30] = nn.Identity()\n        vgg16.avgpool = nn.AdaptiveAvgPool2d(1)\n        vgg16.classifier = nn.Identity()\n        \n        # 固定/不固定特徵層的參數值\n        for param in vgg16.features.parameters():\n            param.requires_grad = features_grad\n        self.backend = vgg16\n         \n        # 增加分類層\n        self.classifier = nn.Sequential(\n          nn.Linear(514, num_classes) # 512: vgg16特徵層結果, 2: age & gender\n        )\n        self.softmax = nn.Softmax(dim=1) # 每一個row的總和都是1\n       \n        for param in self.classifier.parameters():\n            param.requires_grad = True  \n\n    def forward(self, x, age, gender):\n        output = self.backend(x)\n        outputs = torch.cat([output, age.view(-1, 1), gender.view(-1, 1)], dim = 1) # output size = (batch_size, 512), age size = (batch_size), age.view(-1, 1) size = (batch_size, 1), dim = 1; columns concat\n        outputs = self.classifier(outputs) # outputs size = (batch_size, 3)\n        if self.out_prob:\n            outputs = self.softmax(outputs)\n            \n        torch.nn.utils.clip_grad_norm_(self.parameters(), max_norm=self.max_grad_norm)\n        return outputs","metadata":{"execution":{"iopub.status.busy":"2023-11-03T11:36:13.471305Z","iopub.execute_input":"2023-11-03T11:36:13.471640Z","iopub.status.idle":"2023-11-03T11:36:13.484987Z","shell.execute_reply.started":"2023-11-03T11:36:13.471609Z","shell.execute_reply":"2023-11-03T11:36:13.484087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = VGGplus(num_classes = 3)\nprint(model)\ndel model","metadata":{"execution":{"iopub.status.busy":"2023-11-03T11:36:13.486432Z","iopub.execute_input":"2023-11-03T11:36:13.486793Z","iopub.status.idle":"2023-11-03T11:36:14.923322Z","shell.execute_reply.started":"2023-11-03T11:36:13.486760Z","shell.execute_reply":"2023-11-03T11:36:14.922360Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1. 導入 vgg16 的架構和 ImageNet 訓練出來的權重 (**transfer learning**)","metadata":{}},{"cell_type":"code","source":"vgg16 = models.vgg16(weights='IMAGENET1K_V1', progress = True)\nprint(vgg16)","metadata":{"execution":{"iopub.status.busy":"2023-11-03T11:36:14.924537Z","iopub.execute_input":"2023-11-03T11:36:14.924835Z","iopub.status.idle":"2023-11-03T11:36:16.321295Z","shell.execute_reply.started":"2023-11-03T11:36:14.924808Z","shell.execute_reply":"2023-11-03T11:36:16.320166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"以下簡單介紹vgg16中使用到的函式: (以下函式的輸入都需要四個維度: (N = number of data, C = number of channels, H = Height, W = Width))","metadata":{}},{"cell_type":"markdown","source":"> [Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html)(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n\n> * 3: in_channels\n> * 64: out_channels \n> * stride = (1, 1): kernel的移動由左至右, 由上至下, 步長皆為1\n> * padding = (1, 1): 在輸入的周圍填充一層0\n\n> Note:\n> * 雖然是2d的convolution, 但實際的輸入是和kernel都是3維陣列, 而2d指的是kernel移動的方向。\n> * 因為1個(3, 3, 3)的kernel和1個bias遍歷一次輸入就會產生一層輸出, 這邊的輸出有64層, 就需要64個(3, 3, 3)的kernal和對應的64個bias。\n> * 這樣的stride和padding的設定可以讓輸出和輸入的長寬不變。","metadata":{}},{"cell_type":"markdown","source":"![](https://discuss.pytorch.org/uploads/default/original/3X/6/0/60994f2ed1f8c34ee6e83741e2e87fca0a1b4655.jpeg)","metadata":{}},{"cell_type":"code","source":"m = nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\nprint(m)\ninput = torch.randn(1, 3, 50, 50)\nprint(input.shape)\noutput = m(input)\nprint(output.shape)\nfor param in m.parameters():\n    print(param.shape)\n    \ndel m, input, output","metadata":{"execution":{"iopub.status.busy":"2023-11-03T11:36:16.322690Z","iopub.execute_input":"2023-11-03T11:36:16.323007Z","iopub.status.idle":"2023-11-03T11:36:16.333528Z","shell.execute_reply.started":"2023-11-03T11:36:16.322981Z","shell.execute_reply":"2023-11-03T11:36:16.332608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> [MaxPool2d](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d)(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n\n> * ceil_mode: True = 將不足的邊用NAN補齊, False = 將不足的邊直接刪除","metadata":{}},{"cell_type":"code","source":"input = torch.tensor([[1, 1, 1], [2, 2, 2], [3, 3, 3]]).reshape(1, 1, 3, 3).float()\nprint(input)\n\nprint(\"ceil_mode = False\")\nm1 = nn.MaxPool2d(2, stride=2, ceil_mode = False)\noutput1 = m1(input)\nprint(output1)\n\nprint(\"ceil_mode = True\")\nm2 = nn.MaxPool2d(2, stride=2, ceil_mode = True)\noutput2 = m2(input)\nprint(output2)\n\ndel m1, m2, input, output1, output2","metadata":{"execution":{"iopub.status.busy":"2023-11-03T11:36:16.334833Z","iopub.execute_input":"2023-11-03T11:36:16.335202Z","iopub.status.idle":"2023-11-03T11:36:16.345028Z","shell.execute_reply.started":"2023-11-03T11:36:16.335169Z","shell.execute_reply":"2023-11-03T11:36:16.344326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> [AdaptiveAvgPool2d](https://pytorch.org/docs/stable/generated/torch.nn.AdaptiveAvgPool2d.html)(output_size=(7, 7)) \n\n> 按照期望的輸出大小對輸入做平均","metadata":{}},{"cell_type":"code","source":"input = torch.tensor([[1, 1, 1], [2, 2, 2], [3, 3, 3]]).reshape(1, 1, 3, 3).float()\nprint(input)\n\nm7 = nn.AdaptiveAvgPool2d(output_size=(7, 7))\noutput = m7(input)\nprint(output)\n\nm2 = nn.AdaptiveAvgPool2d(output_size=(2, 2))\noutput = m2(input)\nprint(output)\n\ndel input, m7, m2, output","metadata":{"execution":{"iopub.status.busy":"2023-11-03T11:36:16.346817Z","iopub.execute_input":"2023-11-03T11:36:16.347641Z","iopub.status.idle":"2023-11-03T11:36:16.360280Z","shell.execute_reply.started":"2023-11-03T11:36:16.347599Z","shell.execute_reply":"2023-11-03T11:36:16.359337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"雖然AdaptiveAvgPool2d()的輸出大小可以大於輸入大小，但這種作法可能導致訊息的丟失。","metadata":{}},{"cell_type":"markdown","source":"### 2. 觀察 vgg16 的 Output Shape 去設計 feature layers 和 classifier layers 之間的連接層","metadata":{}},{"cell_type":"code","source":"# 因summary()的input存在GPU中, 要將model也移至GPU上才能運行\n\nvgg16.to(config.device)\nsummary(vgg16, input_size = (3, 50, 50)) ","metadata":{"execution":{"iopub.status.busy":"2023-11-03T11:36:16.361346Z","iopub.execute_input":"2023-11-03T11:36:16.361639Z","iopub.status.idle":"2023-11-03T11:36:16.519049Z","shell.execute_reply.started":"2023-11-03T11:36:16.361614Z","shell.execute_reply":"2023-11-03T11:36:16.518145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"在ReLU-30得到的輸出大小已經是(512, 3, 3), 如果使用模型中的MaxPool2d-31:MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, **ceil_mode=False**), 會有些資訊被忽略, 所以接下來會更改31層和32層。","metadata":{}},{"cell_type":"code","source":"vgg16.features[30] = nn.Identity()\nvgg16.avgpool = nn.AdaptiveAvgPool2d(1)\nvgg16.classifier = nn.Identity()\nsummary(vgg16, (3, 50, 50))","metadata":{"execution":{"iopub.status.busy":"2023-11-03T11:36:16.520304Z","iopub.execute_input":"2023-11-03T11:36:16.520594Z","iopub.status.idle":"2023-11-03T11:36:16.533066Z","shell.execute_reply.started":"2023-11-03T11:36:16.520569Z","shell.execute_reply":"2023-11-03T11:36:16.532224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Note: \n* 在avgpool和classifier之間, vgg16模型會把(-1, 512, 1, 1)reshape成(-1, 512)。\n* 每一個(3, 50, 50)的影像經過更改後的vgg16模型就會產生512個數值。","metadata":{}},{"cell_type":"markdown","source":"### 3. 增加影像之外的變數(ex. 性別, 年齡, ...)去建立 classifier layers\n\n這裡想建立一個特徵層可以考慮剛剛影像經過特徵層所得到的512個數值和性別, 年齡這兩個數值, 所以分類層的一開始會有512+2 = 514個神經元。","metadata":{}},{"cell_type":"code","source":"del vgg16","metadata":{"execution":{"iopub.status.busy":"2023-11-03T11:36:16.534376Z","iopub.execute_input":"2023-11-03T11:36:16.534674Z","iopub.status.idle":"2023-11-03T11:36:16.539475Z","shell.execute_reply.started":"2023-11-03T11:36:16.534649Z","shell.execute_reply":"2023-11-03T11:36:16.538501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ResNetplus(nn.Module):\n    def __init__(self, num_classes, input_size = (3, 50, 50), out_prob = True, features_grad = False): # 默認輸出為分到每一類的機率\n        super().__init__()\n        self.max_grad_norm = 0.1  # 設定梯度裁剪的閾值\n       \n        \n        # 決定是否要將輸出轉換為機率\n        self.out_prob = out_prob\n        \n        # 取出vgg16中的特徵層\n        resnet = models.resnet50(weights='IMAGENET1K_V1', progress = True)\n\n        resnet = nn.Sequential(*list(resnet.children())[:-2])\n        # Add your custom layers\n        custom_layers = [\n            nn.AdaptiveAvgPool2d(1),\n            nn.Flatten(),\n            nn.Linear(2048, 1024),\n            nn.ReLU()]\n        custom_layers = nn.Sequential(*custom_layers)\n        # Create a new Sequential model by combining resnet and custom_layers\n        resnet = nn.Sequential(resnet, custom_layers)\n\n\n\n        # 固定/不固定特徵層的參數值 \n        for param in resnet.parameters():\n            param.requires_grad = features_grad\n        self.backend = resnet \n\n        # 增加分類層\n        self.classifier = nn.Sequential(\n          nn.Linear(1026, num_classes) \n        )\n        self.softmax = nn.Softmax(dim=1) # 每一個row的總和都是1\n        \n       \n       \n\n    def forward(self, x, age, gender):\n        output = self.backend(x)\n        outputs = torch.cat([output, age.view(-1, 1), gender.view(-1, 1)], dim = 1) # output size = (batch_size, 512), age size = (batch_size), age.view(-1, 1) size = (batch_size, 1), dim = 1; columns concat\n        outputs = self.classifier(outputs) # outputs size = (batch_size, 3)\n        if self.out_prob:\n            outputs = self.softmax(outputs)\n        # 执行梯度裁剪\n       \n        torch.nn.utils.clip_grad_norm_(self.parameters(), max_norm=self.max_grad_norm)\n\n        return outputs","metadata":{"execution":{"iopub.status.busy":"2023-11-03T11:36:16.540660Z","iopub.execute_input":"2023-11-03T11:36:16.540926Z","iopub.status.idle":"2023-11-03T11:36:16.553046Z","shell.execute_reply.started":"2023-11-03T11:36:16.540902Z","shell.execute_reply":"2023-11-03T11:36:16.552111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\"\nresnet = models.resnet50(weights='IMAGENET1K_V1', progress = True)\nmodel_state = resnet.state_dict()\nprint(\"model_state type:\", type(model_state))\nfor param_tensor in model_state:\n    print(\"name:\", param_tensor)\n    print(\"value:\", model_state[param_tensor])\n    \"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-11-03T11:36:16.554176Z","iopub.execute_input":"2023-11-03T11:36:16.554434Z","iopub.status.idle":"2023-11-03T11:36:16.568573Z","shell.execute_reply.started":"2023-11-03T11:36:16.554411Z","shell.execute_reply":"2023-11-03T11:36:16.567589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resnet = models.resnet50(weights='IMAGENET1K_V1', progress = True)\nresnet = nn.Sequential(*list(resnet.children())[:-2])\n\n# Add your custom layers\ncustom_layers = [\n    nn.AdaptiveAvgPool2d(1),\n    nn.Flatten(),\n    nn.Linear(2048, 1024),\n    nn.ReLU(),\n    nn.Dropout(0.3)\n]\ncustom_layers = nn.Sequential(*custom_layers)\n\n# Create a new Sequential model by combining resnet and custom_layers\nresnet = nn.Sequential(resnet, custom_layers)\n\n\n\nresnet.to(config.device)\nsummary(resnet, input_size = (3, 50, 50))","metadata":{"execution":{"iopub.status.busy":"2023-11-03T11:36:16.569634Z","iopub.execute_input":"2023-11-03T11:36:16.569895Z","iopub.status.idle":"2023-11-03T11:36:17.461307Z","shell.execute_reply.started":"2023-11-03T11:36:16.569871Z","shell.execute_reply":"2023-11-03T11:36:17.460169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train & test dataframe\n    train_df = pd.read_csv(config.root+'/train.csv')\n    test_df = pd.read_csv(config.root+'/test.csv')\n\n   \n    dataset = ParkinsonsDataset(train_df, transforms = My_transforms)\n  \n    test_dataset = ParkinsonsDataset(test_df, transforms = My_transforms)\n    \n    # split training & validation dataset \n    n = len(dataset)\n    valid_size = int(n * config.valid_prob)\n    train_ids , valid_ids = train_test_split(\n     np.linspace(0, n - 1, n).astype(\"int\"),\n     test_size = valid_size,\n     random_state = config.seed,\n    )\n    print(f'Number of samples in train_dataset: {Counter(dataset.labels[train_ids])}')\n    print(f'Number of samples in val_dataset: {Counter(dataset.labels[valid_ids])}')\n    \n    # DataLoader\n    train_dataset = Subset(dataset, train_ids)\n    valid_dataset = Subset(dataset, valid_ids)\n    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=config.batch_size_VGG, shuffle=True)\n    valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=config.batch_size_VGG, shuffle=False)\n    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=config.batch_size_VGG, shuffle=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def VGG_modeling():\n\n    seed_everything(config.seed)\n\n    # train & test dataframe\n    train_df = pd.read_csv(config.root+'/train.csv')\n    test_df = pd.read_csv(config.root+'/test.csv')\n\n    # Dataset\n    print(\"VGG16\")\n    print(\"Initializing dataset...\")\n    dataset = ParkinsonsDataset(train_df, transforms = My_transforms)\n    print(\"Initializing test_dataset...\")\n    test_dataset = ParkinsonsDataset(test_df, transforms = My_transforms)\n    \n    # split training & validation dataset \n    n = len(dataset)\n    valid_size = int(n * config.valid_prob)\n    train_ids , valid_ids = train_test_split(\n     np.linspace(0, n - 1, n).astype(\"int\"),\n     test_size = valid_size,\n     random_state = config.seed,\n    )\n    print(f'Number of samples in train_dataset: {Counter(dataset.labels[train_ids])}')\n    print(f'Number of samples in val_dataset: {Counter(dataset.labels[valid_ids])}')\n    \n    # DataLoader\n    train_dataset = Subset(dataset, train_ids)\n    valid_dataset = Subset(dataset, valid_ids)\n    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=config.batch_size_VGG, shuffle=True)\n    valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=config.batch_size_VGG, shuffle=False)\n    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=config.batch_size_VGG, shuffle=False)\n\n    # settings\n    print(\"VGG16 training\")\n    print(\"Initializing model...\")\n    num_classes = len(Counter(dataset.labels[train_ids]))\n    model = VGGplus(num_classes = num_classes, features_grad = True)\n    model.to(config.device)\n    criterion = nn.CrossEntropyLoss().to(config.device)\n    optimizer = torch.optim.Adam(model.parameters(), lr = config.lr_VGG, weight_decay = config.weight_decay_VGG)\n    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n        optimizer = optimizer,\n        epochs = config.epochs_VGG,\n        steps_per_epoch = train_loader.__len__(),\n        max_lr = config.lr_VGG,\n        anneal_strategy = 'cos'\n    )\n\n    # recordings\n    best_val_loss = float(\"inf\")\n    history = {\n      \"train\": {\n          \"loss\": [],\n          \"acc\": [],\n          \"f1\": []\n      },\n      \"valid\": {\n          \"loss\": [],\n          \"acc\": [],\n          \"f1\": []\n      },\n    }\n    \n    for epoch in range(config.epochs_VGG):\n        train_loss, train_acc, train_f1 = train_one_epoch(model, train_loader, optimizer, scheduler, criterion, config.device)\n        valid_loss, valid_acc, valid_f1 = validation(model, valid_loader, criterion, config.device)\n        \n        # Log the loss and validation result\n        history[\"train\"][\"loss\"].append(train_loss)\n        history[\"train\"][\"acc\"].append(train_acc)\n        history[\"train\"][\"f1\"].append(train_f1)\n        history[\"valid\"][\"loss\"].append(valid_loss)\n        history[\"valid\"][\"acc\"].append(valid_acc)\n        history[\"valid\"][\"f1\"].append(valid_f1)\n\n        print(f'Epoch[{epoch+1}/{config.epochs_VGG}], Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.2f}%, Train F1: {train_f1:.2f}% | Valid Loss: {valid_loss:.4f}, Valid Accuracy: {valid_acc:.2f}%, Valid F1: {valid_f1:.2f}% | LR: {optimizer.state_dict()[\"param_groups\"][0][\"lr\"]:.6f}')\n\n        if valid_loss < best_val_loss:\n            save_file = {\n                \"model\": model.state_dict(),\n                \"optimizer\": optimizer.state_dict(),\n                \"scheduler\": scheduler.state_dict(),\n                \"epoch\": epoch,\n                \"args\": config\n            }\n            best_val_loss = valid_loss\n            torch.save(save_file, \"checkpoint.pth\")\n            \n    best_ckpt = torch.load(\"checkpoint.pth\", map_location=config.device)\n    model.load_state_dict(best_ckpt[\"model\"])\n\n    print(\"VGG plot\")\n    plt.figure(figsize=(12, 5))\n    plt.subplot(1, 2, 1)\n    plt.plot(range(config.epochs_VGG), history[\"train\"][\"loss\"], label='Training Loss')\n    plt.plot(range(config.epochs_VGG), history[\"valid\"][\"loss\"], label='Validation Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.title('Training and Validation Loss Curves')\n    plt.show()\n\n    plt.figure(figsize=(12, 5))\n    plt.subplot(1, 2, 1)\n    plt.plot(range(config.epochs_VGG), history[\"train\"][\"acc\"], label='Training Acc')\n    plt.plot(range(config.epochs_VGG), history[\"valid\"][\"acc\"], label='Validation Acc')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.title('Training and Validation Accuracy Curves')\n    plt.show()\n\n    plt.figure(figsize=(12, 5))\n    plt.subplot(1, 2, 1)\n    plt.plot(range(config.epochs_VGG), history[\"train\"][\"f1\"], label='Training F1')\n    plt.plot(range(config.epochs_VGG), history[\"valid\"][\"f1\"], label='Validation F1')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.title('Training and Validation F1 Score Curves')\n    plt.show()\n    \n    test_prediction_pro, test_prediction_stage = test(model, test_loader, config.device)\n    # 读取现有的test.csv文件\n    test_df = pd.read_csv('/kaggle/input/d/chieh7/hw2-data/hwk02_data/test.csv')\n\n    # 创建一个DataFrame包含预测结果\n    predictions = pd.DataFrame(test_prediction_pro, columns=[f'Stage({i+1})' for i in range(3)])\n    predictions['Stage'] = test_prediction_stage\n    # 将预测结果添加到现有DataFrame中\n    test_df['Stage 1'] = predictions['Stage(1)']\n    test_df['Stage 2'] = predictions['Stage(2)']\n    test_df['Stage 3'] = predictions['Stage(3)']\n    test_df['Stage'] = predictions['Stage']\n    # 另存为新的CSV文件\n    test_df.to_csv('VGG16.csv', index=False)\n    print(\"VGG16 save\")\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-03T11:36:17.466708Z","iopub.execute_input":"2023-11-03T11:36:17.467074Z","iopub.status.idle":"2023-11-03T11:36:17.496713Z","shell.execute_reply.started":"2023-11-03T11:36:17.467023Z","shell.execute_reply":"2023-11-03T11:36:17.495882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv(config.root+'/test.csv')\ntest_dataset = ParkinsonsDataset(test_df, transforms = My_transforms)\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=config.batch_size_VGG, shuffle=False)\nwith torch.no_grad():\n    for batch in test_loader:\n        images, ages, genders, labels = batch  # 解包四个值\n        # 打印一些信息以调试\n        print(images.shape, ages.shape, genders.shape, labels.shape)","metadata":{"execution":{"iopub.status.busy":"2023-11-03T11:36:17.497866Z","iopub.execute_input":"2023-11-03T11:36:17.498198Z","iopub.status.idle":"2023-11-03T11:36:17.675429Z","shell.execute_reply.started":"2023-11-03T11:36:17.498158Z","shell.execute_reply":"2023-11-03T11:36:17.674314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def RseNet_modeling():\n\n    seed_everything(config.seed)\n\n    # train & test dataframe\n    train_df = pd.read_csv(config.root+'/train.csv')\n    test_df = pd.read_csv(config.root+'/test.csv')\n\n    # Dataset\n    print(\"ResNet 50\")\n    print(\"Initializing dataset...\")\n    dataset = ParkinsonsDataset(train_df, transforms = My_transforms)\n    print(\"Initializing test_dataset...\")\n    test_dataset = ParkinsonsDataset(test_df, transforms = My_transforms)\n    \n    # split training & validation dataset \n    n = len(dataset)\n    valid_size = int(n * config.valid_prob)\n    train_ids , valid_ids = train_test_split(\n     np.linspace(0, n - 1, n).astype(\"int\"),\n     test_size = valid_size,\n     random_state = config.seed,\n    )\n    print(f'Number of samples in train_dataset: {Counter(dataset.labels[train_ids])}')\n    print(f'Number of samples in val_dataset: {Counter(dataset.labels[valid_ids])}')\n    \n    # DataLoader\n    train_dataset = Subset(dataset, train_ids)\n    valid_dataset = Subset(dataset, valid_ids)\n    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=config.batch_size_Res, shuffle=True)\n    valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=config.batch_size_Res, shuffle=False)\n    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=config.batch_size_Res, shuffle=False)\n\n    # settings\n    print(\"ResNet50 training\")\n    print(\"Initializing model...\")\n    num_classes = len(Counter(dataset.labels[train_ids]))\n    model =  ResNetplus(num_classes = num_classes, features_grad = True)\n    model.to(config.device)\n    criterion = nn.CrossEntropyLoss().to(config.device)\n    optimizer = torch.optim.Adam(model.parameters(), lr = config.lr_Res, weight_decay = config.weight_decay_Res)\n    \n    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n        optimizer = optimizer,\n        epochs = config.epochs_Res,\n        steps_per_epoch = train_loader.__len__(),\n        max_lr = config.lr_Res,\n        anneal_strategy = 'cos'\n    )\n\n    # recordings\n    best_val_loss = float(\"inf\")\n    history = {\n      \"train\": {\n          \"loss\": [],\n          \"acc\": [],\n          \"f1\": []\n      },\n      \"valid\": {\n          \"loss\": [],\n          \"acc\": [],\n          \"f1\": []\n      },\n    }\n\n    for epoch in range(config.epochs_Res):\n        train_loss, train_acc, train_f1 = train_one_epoch(model, train_loader, optimizer, scheduler, criterion, config.device)\n        valid_loss, valid_acc, valid_f1 = validation(model, valid_loader, criterion, config.device)\n        \n        # Log the loss and validation result\n        history[\"train\"][\"loss\"].append(train_loss)\n        history[\"train\"][\"acc\"].append(train_acc)\n        history[\"train\"][\"f1\"].append(train_f1)\n        history[\"valid\"][\"loss\"].append(valid_loss)\n        history[\"valid\"][\"acc\"].append(valid_acc)\n        history[\"valid\"][\"f1\"].append(valid_f1)\n\n        print(f'Epoch[{epoch+1}/{config.epochs_Res}], Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.2f}%, Train F1: {train_f1:.2f}% | Valid Loss: {valid_loss:.4f}, Valid Accuracy: {valid_acc:.2f}%, Valid F1: {valid_f1:.2f}% | LR: {optimizer.state_dict()[\"param_groups\"][0][\"lr\"]:.6f}')\n\n        if valid_loss < best_val_loss:\n            save_file = {\n                \"model\": model.state_dict(),\n                \"optimizer\": optimizer.state_dict(),\n                \"scheduler\": scheduler.state_dict(),\n                \"epoch\": epoch,\n                \"args\": config\n            }\n            best_val_loss = valid_loss\n            torch.save(save_file, \"checkpoint2.pth\")\n\n    best_ckpt = torch.load(\"checkpoint2.pth\", map_location=config.device)\n    model.load_state_dict(best_ckpt[\"model\"])\n\n    print(\"ResNet 50 plot\")\n    plt.figure(figsize=(12, 5))\n    plt.subplot(1, 2, 1)\n    plt.plot(range(config.epochs_Res), history[\"train\"][\"loss\"], label='Training Loss')\n    plt.plot(range(config.epochs_Res), history[\"valid\"][\"loss\"], label='Validation Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.title('Training and Validation Loss Curves')\n    plt.show()\n\n    plt.figure(figsize=(12, 5))\n    plt.subplot(1, 2, 1)\n    plt.plot(range(config.epochs_Res), history[\"train\"][\"acc\"], label='Training Acc')\n    plt.plot(range(config.epochs_Res), history[\"valid\"][\"acc\"], label='Validation Acc')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.title('Training and Validation Accuracy Curves')\n    plt.show()\n\n    plt.figure(figsize=(12, 5))\n    plt.subplot(1, 2, 1)\n    plt.plot(range(config.epochs_Res), history[\"train\"][\"f1\"], label='Training F1')\n    plt.plot(range(config.epochs_Res), history[\"valid\"][\"f1\"], label='Validation F1')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.title('Training and Validation F1 Score Curves')\n    plt.show()\n    \n    test_prediction_pro, test_prediction_stage =  test(model, test_loader, config.device)\n  \n    # 读取现有的test.csv文件\n    test_df = pd.read_csv('/kaggle/input/d/chieh7/hw2-data/hwk02_data/test.csv')\n\n    # 创建一个DataFrame包含预测结果\n    predictions = pd.DataFrame(test_prediction_pro, columns=[f'Stage({i+1})' for i in range(3)])\n    predictions['Stage'] = test_prediction_stage\n    # 将预测结果添加到现有DataFrame中\n    test_df['Stage 1'] = predictions['Stage(1)']\n    test_df['Stage 2'] = predictions['Stage(2)']\n    test_df['Stage 3'] = predictions['Stage(3)']\n    test_df['Stage'] = predictions['Stage']\n    # 另存为新的CSV文件\n    test_df.to_csv('ResNet50.csv', index=False)\n    print(\"ResNet save\")\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-03T11:36:17.676978Z","iopub.execute_input":"2023-11-03T11:36:17.677348Z","iopub.status.idle":"2023-11-03T11:36:17.707355Z","shell.execute_reply.started":"2023-11-03T11:36:17.677318Z","shell.execute_reply":"2023-11-03T11:36:17.706303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def main():\n    VGG_modeling()\n    RseNet_modeling()\n    \n    \nif __name__ == \"__main__\":\n    main()","metadata":{"execution":{"iopub.status.busy":"2023-11-03T11:36:17.708513Z","iopub.execute_input":"2023-11-03T11:36:17.708806Z","iopub.status.idle":"2023-11-03T11:40:52.375662Z","shell.execute_reply.started":"2023-11-03T11:36:17.708781Z","shell.execute_reply":"2023-11-03T11:40:52.374775Z"},"trusted":true},"execution_count":null,"outputs":[]}]}